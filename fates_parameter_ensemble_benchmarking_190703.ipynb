{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FATES parameter ensemble evaluation \n",
    "\n",
    "This code evaluates the performance of 287 parameter ensemble member simulations against observations at a tropical forest test site, Barro Colorado Island, Panama. Parameter ensemble member simulations are identical (same model structure, initial conditions, and meteorological forcing) except that they differ in 12 plant trait parameters. Values for these plant trait parameters were sampled from observationally constrained distributions when possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data\n",
    "\n",
    "Here we load the data and calculate time series of annual mean values for six ecosystem characteristics for all the simulations and observations. This code section returns two multidimensional arrays, one for model output and one for observations, that contain annual mean values for each variable organized by parameter set and background carbon dioxide concentration.\n",
    "\n",
    "The six ecosystem characteristics included in these arrays are:\n",
    "\n",
    "- Leaf area index,\n",
    "- Above-ground biomass,\n",
    "- Basal area,\n",
    "- Gross primary productivity,\n",
    "- Latent heat flux, and\n",
    "- Sensible heat flux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annmeants(filepath,var,varfiletype,nyrs,conv_factor):\n",
    "    ''' Calculate time series of annual means for a model output variable.\n",
    "    :param filepath (str): file path to data file\n",
    "    :param var (str): name of variable to call from filename\n",
    "    :param nyrs (int, float): number of years to analyze\n",
    "    :param conv_factor (float): conversion factor specific to variable specified by var\n",
    "    :return: 2-D array containing annual mean time series (ensemble member, nyrs)\n",
    "    '''\n",
    "    \n",
    "    # If model output is stored as monthly average for all tree sizes,\n",
    "    # need to calculate annual mean.   \n",
    "    if varfiletype == 0:\n",
    "        \n",
    "        # Load monthly time series\n",
    "        # For all cases except latent heat flux (FLH):\n",
    "        if var != 'FLH':\n",
    "            mthts_temp = nc4.Dataset(filepath).variables[var][:,:,0]\n",
    "        \n",
    "        # For the special case of latent heat flux:\n",
    "        elif var == 'FLH':\n",
    "            # Sum of three terms:\n",
    "            mthts_temp = (nc4.Dataset(filepath).variables['FCTR'][:,:,0] \n",
    "                          + nc4.Dataset(filepath).variables['FGEV'][:,:,0] \n",
    "                          + nc4.Dataset(filepath).variables['FCEV'][:,:,0])\n",
    "        \n",
    "        \n",
    "        # Calculate annual mean time series for nyrs and convert units if necessary\n",
    "        annmeants = np.nanmean(np.reshape((mthts_temp[:,int(-1*nyrs*12):] * conv_factor),\n",
    "                                          (mthts_temp.shape[0],-1,12)),axis=2)\n",
    "        \n",
    "    # Else if model output is stored as annual mean but structured by tree size,\n",
    "    # need to sum across tree sizes.\n",
    "    elif varfiletype == 1:\n",
    "        # Calculate annual mean time series for entire ecosystem by summing across tree sizes\n",
    "        annmeants = np.squeeze(np.nansum((\n",
    "                        nc4.Dataset(filepath).variables[var + '_SCLS'][:,int(-1*nyrs):,:]),\n",
    "                        axis=2))\n",
    "    \n",
    "    mthts_temp = None\n",
    "    \n",
    "    return annmeants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will specify the information required to load and calculate annual mean time series of model output for each simulation, including file paths and names, variables to analyze, and conversion factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "model_filepath = 'data/'\n",
    "\n",
    "# Filenames\n",
    "# {1} = carbon dioxide concentration specified by CO2level;\n",
    "# {2} = variable file type specified by varfiletype.\n",
    "model_filenames =[\n",
    "    'fates_clm5_fullmodel_bci_parameter_ensemble_1pft_slaprofile_{}_v001.I2000Clm50FatesGs.Cdf9b02d-Fb178808.2018-07-27.h{}.ensemble.sofar.nc',\n",
    "    'fates_clm5_fullmodel_bci_parameter_ensemble_1pft_slaprofile_{}_v001.I2000Clm50FatesGs.Cdf9b02d-Fb178808.2018-07-27.h{}.ensemble.sofar.nc']\n",
    "\n",
    "# Background carbon dioxide (CO2) concentration\n",
    "CO2levels = ['367ppm', '400ppm']\n",
    "\n",
    "# Variable list for model output\n",
    "varlist = ['TLAI','AGB','BA','GPP','FLH','FSH']\n",
    "\n",
    "# Data structure for each variable in varlist:\n",
    "# 0 = monthly data for entire ecosystem;\n",
    "# 1 = annual data structured by tree size structure.\n",
    "varfiletype = [0,1,1,0,0,0]\n",
    "\n",
    "# Conversion factor for each variable in varlist:\n",
    "varconv = [1, 1, 1, 86400*365, 1, 1]\n",
    "\n",
    "# Variable units after applying conversion factor for each variable in varlist:\n",
    "varunits = ['$m^2/m^2$','$kgC/m^2$','$m^2/ha$','$gC/m^2/yr$','$W/m^2$','$W/m^2$']\n",
    "\n",
    "# Number of years of model output to analyze\n",
    "nyrs = 50\n",
    "\n",
    "# Number of parameter sets in ensemble\n",
    "nens = nc4.Dataset(model_filepath + model_filenames[0].format(CO2levels[0],varfiletype[0])).variables[varlist[0]].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a multidimensional array that contains a time series of annual means for each variable, parameter set and background carbon dioxide concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: model_data, a 4-D array of annual mean values for\n",
    "    # each variable with dimensions\n",
    "    # (CO2levels, varlist, nens, nyrs)\n",
    "    # with the following indexing:\n",
    "    # CO2levels: \n",
    "    #         0 = 367ppm CO2; \n",
    "    #         1 = 400ppm CO2.\n",
    "    # varlist: \n",
    "    #         0 = Leaf area index;\n",
    "    #         1 = Above ground biomass;\n",
    "    #         2 = Basal area;\n",
    "    #         3 = Gross primary productivity;\n",
    "    #         4 = Latent heat flux;\n",
    "    #         5 = Sensible heat flux.\n",
    "    # nens: \n",
    "    #         0:286 = parameter set index.\n",
    "\n",
    "# Initialize array\n",
    "model_data = np.zeros([len(CO2levels), len(varlist), nens, nyrs])\n",
    "\n",
    "for c in range(len(CO2levels)):\n",
    "    for v in range(len(varlist)):\n",
    "        \n",
    "        filepath = model_filepath + model_filenames[c].format(CO2levels[c],varfiletype[v])\n",
    "        \n",
    "        model_data[c, v, :, :] = annmeants(filepath, varlist[v], varfiletype[v], nyrs, varconv[v])\n",
    "\n",
    "        filepath = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaf area index\n",
    "\n",
    "Leaf area index observations come from Detto et al. (2018) and were made using hemispherical photographs taken approximately monthly from January 2015 to August 2017 at 188 locations at our test site, Barro Colorado Island, Panama. We calculate annual mean values from the monthly means reported by Detto et al. (2018). (Note that monthly data consists of spatial means across photograph locations, rather than temporal means.) In order to use all the data available\n",
    "\n",
    "We calculate two time series of annual means - one starting in from January and the second starting from August. This allows us to use all of the data available in our annual means analysis, despite have observations that span a partial year (ending in August rather than December of the last year).\n",
    "\n",
    "Data was captured from Detto et al. (2018) Figure 7a using GraphClick software.\n",
    "\n",
    "__Reference for Data:__\n",
    "\n",
    "Detto, M., Wright, S. J., Calderón, O., & Muller-Landau, H. C. (2018). Resource acquisition and reproductive strategies of tropical forest in response to the El Niño-Southern Oscillation. Nature Communications, 9(1), 913. https://doi.org/10.1038/s41467-018-03306-9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_lai: 2D array containing annual mean leaf area index [sample number, years]\n",
    "#    sample: 0 = sample months starting from January; 1 = starting from Sept\n",
    "#    Note. As observations consist of 2 years and 8 months of data, we sample both\n",
    "#    the first set of full years (starting in January) and last set of full years\n",
    "#    (starting in September)\n",
    "\n",
    "# File path\n",
    "filepath = 'data/LAI_Detto2018Obs.csv'\n",
    "\n",
    "# Monthly spatial means\n",
    "lai_mthts = np.asarray([col[2] for col in (pd.read_csv(filepath)).values])\n",
    "\n",
    "# Specify start months for observations\n",
    "startmonth_list = np.array([1,9])\n",
    "\n",
    "# Number of annual means per sample\n",
    "nyears_lai = round(len(lai_mthts)/12-0.5)\n",
    "\n",
    "# Initialize array\n",
    "obs_data_lai = np.zeros([len(startmonth_list), nyears_lai])\n",
    "\n",
    "# Calculate annual means and fill array\n",
    "for x in range(len(startmonth_list)):\n",
    "    obs_data_lai[x,:] = np.nanmean(np.reshape(lai_mthts[startmonth_list[x]-1:24+startmonth_list[x]-1],(nyears_lai,12)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above-ground carbon biomass\n",
    "\n",
    "Above-ground carbon biomass estimates were calculated from a 1995 census survey at our test site, Barro Colorado Island, by Meakem et al. (2018). They estimated above-ground biomass using two different methods (the standard and Chave allometric formulations) which we use to represent uncertainty in the observational estimate. \n",
    "\n",
    "Alternatively, we can estimate above-ground carbon biomass from estimates of total biomass from census survey data reproted in Baraloto et al. (2013) and Feeley et al. (2007) for the following years:  1985, 1990,1995, 2000, and 2005. This alternative method yields similar results and can be implemented by setting use_alt_agb_obs to 1 below.\n",
    "\n",
    "__References for Data:__\n",
    "\n",
    "Meakem, V., Tepley, A. J., Gonzalez-Akre, E. B., Herrmann, V., Muller-Landau, H. C., Wright, S. J., et al. (2018). Role of tree size in moist tropical forest carbon cycling and water deficit responses. New Phytologist, 219, 947–958. https://doi.org/doi:10.1111/nph.14633\n",
    "<br>\n",
    " \n",
    "Baraloto, C., Molto, Q., Rabaud, S., Hérault, B., Valencia, R., Blanc, L., et al. (2013). Rapid simultaneous estimation of aboveground biomass and tree diversity across Neotropical forests: a comparison of field inventory methods. Biotropica, 45(3), 288–298. https://doi.org/10.1111/btp.12006 \n",
    "<br>\n",
    "\n",
    "Feeley, K. J., Davies, S. J., Ashton, P. S., Bunyavejchewin, S., Supardi, M. N., Kassim, A. R., et al. (2007). The role of gap phase processes in the biomass dynamics of tropical forests. Proceedings of the Royal Society of London B: Biological Sciences, 274(1627), 2857–2864. https://doi.org/10.1098/rspb.2007.0954\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_agb: vector of above ground biomass (KgC/m2)\n",
    "#    from estimates from Meakem et al. 2018 [allometry calculation] \n",
    "#   allometry calculation: 0 = standard, 1 = Chave\n",
    "\n",
    "use_alt_agb_obs = 0;\n",
    "\n",
    "filepath = 'data/BCI_biomass.csv'\n",
    "\n",
    "if use_alt_agb_obs == 0:\n",
    "    # Above-ground carbon biomass from Meakem et al. 2018 (MgC/ha) \n",
    "    cbiomass_obs_Mgha = np.asarray([col[2] for col in (pd.read_csv(filepath)).values])[-2:,]\n",
    "    # Convert from MgC/ha to KgC/m2\n",
    "    ha_to_m2 = 1/10000\n",
    "    Mg_to_kg = 1000\n",
    "    obs_data_agb = cbiomass_obs_Mgha * ha_to_m2 * Mg_to_kg\n",
    "    \n",
    "elif use_alt_agb_obs ==1:\n",
    "    # Total aboveground biomass (Mg biomass/ha) from \n",
    "    # Baraloto et al. (2013) and Feeley et al. (2007)\n",
    "    agb_biomass_obs = np.asarray([col[1] for col in (pd.read_csv(filepath)).values])[:-2,]\n",
    "    # Estimate of carbon biomass from total biomass using \n",
    "    #conversions factor of 0.47 following Meakem et al. 2018\n",
    "    obs_data_agb_v2 = agb_biomass_obs*0.47\n",
    "    obs_data_agb = obs_data_agb_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basal area\n",
    "\n",
    "We use estimates of the median basal area for our test site Barro Colorado Island, Panama, from census surveys conducted in 1999, 2001, 2006, and 2011 by Condit et al. (1998, 2012, 2017) and Hubbell et al. (1999).\n",
    "\n",
    "__References for Data:__\n",
    "\n",
    "Condit, R. S., Aguilar, S., Perez, R., Lao, S., Hubbell, S. P., & Foster, R. B. (2017). Barro Colorado 50-ha Plot Taxonomy as of 2017. https://doi.org/10.25570/stri/10088/32990\n",
    "\n",
    "Condit, R., Lao, S., Pérez, R., Dolins, S. B., Foster, R., & Hubbell, S. (2012). Barro Colorado forest census plot data (version 2012). Center for Tropical Forest Science Databases. Https://Dx. Doi. Org/10.5479/Data. Bci. https://doi.org/http://dx.doi.org/10.5479/data.bci.20130603\n",
    "\n",
    "Condit, R. (1998). Tropical forest census plots. Berlin, Germany, and Georgetown, Texas: Springer-Verlag and R. G. Landes Company.\n",
    "\n",
    "Hubbell, S. P., Foster, R. B., O'Brien, S. T., Harms, K. E., Condit, R., Wechsler, B., et al. (1999). Light-gap disturbances, recruitment limitation, and tree diversity in a neotropical forest. Science, 283(5401), 554–557. https://doi.org/10.1126/science.283.5401.554 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_ba: vector containing basal area (m^2/ha) by census year [years]\n",
    "\n",
    "filepath = 'data/census_bmks_bci_171208.nc'\n",
    "\n",
    "# Load basal area median values for the last 5 census dates\n",
    "# Data structured as follows:\n",
    "# [census number, tree diameter size class,...\n",
    "# distribution percentiles (0.05,0.5,0.95)]\n",
    "basalarea_bysize = nc4.Dataset(filepath).variables['basal_area_by_size_census'][-5:,:,1]\n",
    "\n",
    "# Sum across tree size classes\n",
    "obs_data_ba = np.nansum(basalarea_bysize,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross primary productivity, latent heat fluxes, and sensible heat fluxes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Reference for Data:__\n",
    "\n",
    "Koven, C. D., et al. Benchmarking and Parameter Sensitivity of Predictions of Ecophysiological and Vegetation Dynamics using the Functionally Assembled Terrestrial Ecosystem Simulator (FATES) at Barro Colorado Island, Panama. *In prep.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annmeants_fluxobs(mthts,startmth):\n",
    "    ''' Calculate time series of annual means from monthly fluxtower estimates.\n",
    "    :param mthts (float): 2-D array containing fluxtower observations (years, months)\n",
    "    :param startmth (int): number corresponding to start month for this annual mean time series\n",
    "                            (e.g. 7 = start with July, 9 = start with Sept)\n",
    "    :return: vector containing annual mean time series of size (nyrs) \n",
    "    '''\n",
    "    # Discard number of months specified by dif\n",
    "    mthts_dif = np.reshape(mthts,(1,-1))[:,startmth-1:startmth-1-12]\n",
    "    # Calculate annual mean time series\n",
    "    annmeants = np.nanmean(np.reshape(mthts_dif,(5,12)),axis=1)\n",
    "    \n",
    "    return annmeants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annual mean values for gross primary productivity, latent heat flux, and sensible heat flux\n",
    "# Results in obs_data_flux = annual means indexed by [startmonth (0 = July, 1= Sept), variable, year]\n",
    "#    variable: 0 = gross primary productivity, 1 = latent heat flux, 2 = sensible heat flux\n",
    "#    startmonth: index for annual mean calculations starting from different months\n",
    "#        There are two time series for each variable because the observations span incomplete years.\n",
    "#        To use all data available in our analysis, we calculate have one time series of means \n",
    "#        starting with July and the second starting with Sept (this uses all months available).\n",
    "#    year: year in the annual mean time series\n",
    "\n",
    "# Load observations\n",
    "GPP_data = np.load('data/fluxdata_GPP.npy')\n",
    "LH_data  = np.load('data/fluxdata_LH.npy')\n",
    "SH_data  = np.load('data/fluxdata_SH.npy')\n",
    "fluxdata_mask= np.load('GPP_mask.npy')\n",
    "\n",
    "# Apply mask to arrays\n",
    "GPP_monthyear = np.ma.masked_array(GPP_data, mask=fluxdata_mask)\n",
    "LH_monthyear = np.ma.masked_array(LH_data, mask=fluxdata_mask)\n",
    "SH_monthyear = np.ma.masked_array(SH_data, mask=fluxdata_mask)\n",
    "\n",
    "# Specify start months for observations\n",
    "startmonth_list = np.array([7,9])\n",
    "\n",
    "# Number of years\n",
    "nyrs_obsflux = len(annmeants_fluxobs(GPP_monthyear,startmonth_list[0]))\n",
    "\n",
    "# Initialize array\n",
    "obs_data_flux = np.zeros([len(startmonth_list), 3, nyrs_obsflux])\n",
    "\n",
    "# Fill array\n",
    "for x in range(len(startmonth_list)):\n",
    "    obs_data_flux[x,0,:] = annmeants_fluxobs(GPP_monthyear,startmonth_list[x])\n",
    "    obs_data_flux[x,1,:] = annmeants_fluxobs(LH_monthyear,startmonth_list[x])\n",
    "    obs_data_flux[x,2,:] = annmeants_fluxobs(SH_monthyear,startmonth_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance of each parameter ensemble member against observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #1: Error Rate\n",
    "\n",
    "The error rate measures the percent of model annual means that fall within observed range for each variable and ensemble member.<br>\n",
    "\n",
    "The observed range is defined as the minimum and maximum across observations. To account for relatively small sample sizes and potential measurment error within the observations we extend the observational range by the 10% in either direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return:  error_rate_array: a 4-D array containing error rates\n",
    "#    [case, variable, model ensemble member, degradation level]\n",
    "\n",
    "# Specify names of observed data arrays in order corresponding to varlist\n",
    "obs_data_list = [obs_data_lai,obs_data_agb,obs_data_ba,\n",
    "                 obs_data_flux[:,0,:],obs_data_flux[:,1,:],\n",
    "                 obs_data_flux[:,2,:]]\n",
    "\n",
    "# Degradation level for the observational range (as fraction, not percent)\n",
    "dg = np.array([0.10])\n",
    "\n",
    "#Function to calculate error rate \n",
    "def error_rate(model_ts,obs_ts,dg):\n",
    "    '''Function calculates the error rate, meaning the percentage of\n",
    "    model annual means that fall within the observed range for each model\n",
    "    ensemble member\n",
    "    param model_ts: a 2-D array containing the time series of annual means\n",
    "       for a given variable for all model ensemble members [ensemble member, years]\n",
    "    param obs_ts: an n-D array containing the observed time series for\n",
    "        the given variable\n",
    "    param dg: a vector of any length specifying the levels of range degradation\n",
    "        to test\n",
    "    return error_rate: a 2-D array containing the error rates for each \n",
    "        ensemble member [ensemble member, degradation rates (dg)]'''\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    nens = model_ts.shape[0]\n",
    "    \n",
    "    # Empty array to fill\n",
    "    error_rate = np.zeros([nens])\n",
    "\n",
    "    # Observed minimum and maximum\n",
    "    obs_min = np.nanmin(obs_ts)\n",
    "    obs_max = np.nanmax(obs_ts)\n",
    "    \n",
    "    error_rate = 100*np.nansum(np.where((model_ts <= obs_min*(1-dg)) | (model_ts >= obs_max*(1+dg)),1,0),1)/model_ts.shape[1]\n",
    "    return error_rate\n",
    "\n",
    "\n",
    "# Calculate error rate for all cases and variables\n",
    "error_rate_array = np.zeros([len(model_casenames),len(varlist), nens])\n",
    "for i in range(len(model_casenames)):\n",
    "        for j in range(len(varlist)):\n",
    "            error_rate_array[i,j,:] = error_rate(model_data[i,j,:,:], obs_data_list[j], dg)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #2:  Normalized root mean square error (NRMSE)\n",
    "\n",
    "The normalized root mean square error (NRMSE) measures the distance between each ensemble member's model output from the observed mean and normalizes this distance by the observed range. The normalized root mean square error is calculated for each variable and ensemble member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalized Root Mean Square Error (RMSE/Observed Range)\n",
    "# Returns nrsmse_array a 3-D array containing NRMSE for each \n",
    "#[case, variable, ensemble member]\n",
    "\n",
    "# Function to calculate normalized root mean square errer (nrmse)\n",
    "# When multiple observation time series are available, this function\n",
    "# calculates the nrmse for each time series and then selects the \n",
    "# lowest of those nrmse values.\n",
    "def nrmse(model_ts,obs_ts):\n",
    "    '''Function calculates the normalized root mean square error for each model\n",
    "    ensemble member\n",
    "    param model_ts: a 2-D array containing the time series of annual means\n",
    "       for a given variable for all model ensemble members [ensemble member, years]\n",
    "    param obs_ts: an n-D array containing the observed time series for\n",
    "        the given variable\n",
    "    return nrmse: a vector containing the normalized root mean square error \n",
    "        for each ensemble member [ensemble member]'''\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    nens = model_ts.shape[0]\n",
    "\n",
    "    # If multiple observation time series, \n",
    "    # take the lowest NRMSE for each ensemble member\n",
    "    try:\n",
    "        if obs_ts.shape[1]>0:\n",
    "            # Number of observation time series\n",
    "            nobs = obs_ts.shape[0]\n",
    "            obs_min = np.nanmin(obs_ts,axis=1)\n",
    "            obs_max = np.nanmax(obs_ts, axis=1)\n",
    "            obs_mean = np.nanmean(obs_ts,axis=1)\n",
    "            \n",
    "            temp_nrmse = np.zeros([nobs,nens])\n",
    "            \n",
    "            for obsnum in range(nobs):\n",
    "                temp_nrmse[obsnum,:] = np.sqrt(np.nansum((obs_mean[obsnum] - model_ts[:,:])**2,axis=1) / model_ts.shape[1]) / (obs_max[obsnum]-obs_min[obsnum])\n",
    "                \n",
    "            nrmse = np.nanmin(temp_nrmse,axis=0)\n",
    "\n",
    "            temp_nrmse = None\n",
    "        \n",
    "    # Otherwise, simply calculate NRMSE\n",
    "    except IndexError:\n",
    "        obs_min = np.nanmin(obs_ts,axis=0)\n",
    "        obs_max = np.nanmax(obs_ts,axis=0)\n",
    "        obs_mean = np.nanmean(obs_ts,axis=0)    \n",
    "        \n",
    "        nrmse = np.sqrt(np.nansum((obs_mean - model_ts[:,:])**2,axis=1) / model_ts.shape[1]) / (obs_max-obs_min)\n",
    "\n",
    "    return nrmse\n",
    "    \n",
    "\n",
    "# Calculate NRMSE for all cases and variables\n",
    "nrmse_array = np.zeros([len(model_casenames),len(varlist), nens])\n",
    "\n",
    "for i in range(len(model_casenames)):\n",
    "        for j in range(len(varlist)):\n",
    "            nrmse_array[i,j,:] = nrmse(model_data[i,j,:,:], obs_data_list[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average across variables\n",
    "\n",
    "We calculate weighted averages across variables for both the normalized root mean square error and the error rate. We calculate and consider three different weighting approaches to ensure that our selection of high-performing parameter sets is robust to weighting method. These three weighting approaches we use are:\n",
    "\n",
    "1. Even:  All variables are evenly weighted.\n",
    "\n",
    "2. Structure:  This weighting favors structural ecosystem properties (leaf area index, above-ground biomass, and basal area). This weighting scheme reflects the likelihood that structural property measurements at our test site include less uncertainty than flux measurements.\n",
    "\n",
    "3. Correlation: This weighting scheme is informed by correlations between individual variable scores. Ensemble member performance in flux variables (gross primary productivity, sensible heat, and latent heat) was correlated with leaf area index and with one another. As leaf area index observations likely include smaller measurement uncertainty, we chose to weight leaf area index more highly at the expense of flux observations. We also reduced the weightings of basal area and above-ground biomass to account for their correlation with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even weighting across all variables\n",
    "er_wavg_even = np.nansum(error_rate_array,1) / error_rate_array.shape[1]\n",
    "\n",
    "\n",
    "# Weighted average favoring structural properties:\n",
    "# leaf area index, aboveground biomass, basal area\n",
    "w = 0.3\n",
    "er_wavg_strct = ( w*(error_rate_array[:,0,:]) \n",
    "            + w*(error_rate_array[:,1,:])\n",
    "            + w*(error_rate_array[:,2,:])\n",
    "            + (1-3*w)*((error_rate_array[:,3,:])\n",
    "                +(error_rate_array[:,4,:])\n",
    "                +(error_rate_array[:,5,:]))/3)\n",
    "\n",
    "# Alternative weighting based on correlations between error rates across variables\n",
    "# 1. Weighted average giving greatest weight to LAI, then to combination of AGB and BA (which are correlated with one another),\n",
    "# and small weight to fluxes which are correlated with one another and with LAI.\n",
    "w1 = 0.4\n",
    "w2 = 0.25\n",
    "w3 = 0.1\n",
    "er_wavg_corr = ( w1*(error_rate_array[:,0,:])  \n",
    "            + w2*(error_rate_array[:,1,:])  \n",
    "            + w2*(error_rate_array[:,2,:]) \n",
    "            + w3*((error_rate_array[:,3,:])\n",
    "                +(error_rate_array[:,4,:])\n",
    "                +(error_rate_array[:,5,:]))/3)\n",
    "\n",
    "# Note. Code for er_wavg_strct and er_wavg_corr should be updated \n",
    "# to allow the flexibility to add additional variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted average Distance scores\n",
    "# Here we use the weighted Euclidean Distance to calculate the distance of model output from the mean observations in multivariate space:\n",
    "#  Square each variable score before weighting, then take squareroot of the weighted sum;\n",
    "#  Use the time period that fits model output best (e.g. jan vs sept start)\n",
    "\n",
    "\n",
    "# Weighted average with even weighting across all variables\n",
    "w = 1/6\n",
    "nrmse_wavg_even = np.sqrt(w*(nrmse_array[:,0,:])**2 \n",
    "                                  + w*(nrmse_array[:,1,:])**2 \n",
    "                                  + w*(nrmse_array[:,2,:])**2 \n",
    "                                  + w*(nrmse_array[:,3,:])**2 \n",
    "                                  + w*(nrmse_array[:,4,:])**2 \n",
    "                                  + w*(nrmse_array[:,5,:])**2)\n",
    "\n",
    "\n",
    "# Define weighted average favoring LAI, AGB, and BA (our structural properties)\n",
    "w = 0.3\n",
    "nrmse_wavg_strct = np.sqrt(w*(nrmse_array[:,0,:])**2 \n",
    "                        + w*(nrmse_array[:,1,:])**2 \n",
    "                        + w*(nrmse_array[:,2,:])**2 \n",
    "                        + (1-3*w)*((nrmse_array[:,3,:])**2 \n",
    "                                    +(nrmse_array[:,4,:])**2 \n",
    "                                    +(nrmse_array[:,5,:])**2)/3)\n",
    "\n",
    "# Weighted average giving greatest weight to LAI, then to combination of AGB and BA (which are correlated with one another),\n",
    "# and small weight to fluxes which are correlated with one another and with LAI.\n",
    "w1 = 0.4\n",
    "w2 = 0.25\n",
    "w3 = 0.1\n",
    "nrmse_wavg_corr = np.sqrt(w1*(nrmse_array[:,0,:])**2 \n",
    "                          + w2*(nrmse_array[:,1,:])**2 \n",
    "                          + w2*(nrmse_array[:,2,:])**2 \n",
    "                          + w3*((nrmse_array[:,3,:])**2 \n",
    "                                  +(nrmse_array[:,4,:])**2 \n",
    "                                  +(nrmse_array[:,5,:])**2)/3)\n",
    "\n",
    "# Note. The above code should be updated \n",
    "# to allow the flexibility to add additional variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank ensemble members by performance\n",
    "Here we assign an overall rank to each ensemble member based on its performance across both performance metrics (error rate and NRMSE), a three weighting schemes (even, structure, and correlated), and two cases (low and high atmospheric carbon dioxide concentration). The goal of this analysis is to identify parameter ensemble members (and thus parameter sets) that robsutly perform well at our test site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_array = np.stack([er_wavg_even,nrmse_wavg_even,\n",
    "                             er_wavg_strct,nrmse_wavg_strct,\n",
    "                             er_wavg_corr,nrmse_wavg_corr])\n",
    "\n",
    "rank_array = scipy.stats.mstats.rankdata(all_avg_array,axis=2)\n",
    "\n",
    "# Sum ranks across cases and ranking methods\n",
    "sum_rank_array = np.nansum(np.nansum(rank_array,axis=0),axis=0)\n",
    "\n",
    "# Sort the index number for each ensemble member by their summed rank (best to worst performance)\n",
    "sum_rank_index = np.argsort(sum_rank_array)\n",
    "\n",
    "#Print Index # for Top 10 Ensemble Members\n",
    "highperform_num = np.transpose(sum_rank_index)[:10,]+1\n",
    "highperform_indx = np.transpose(sum_rank_index)[:10,]\n",
    "print(\"Highest Performing Ensemble Member Numbers: \", highperform_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance metrics for high-performing and all ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param dg: specifies degradation level of observational range\n",
    "# return error_heatdata: error rates by [case, variable, ensemble member]\n",
    "# return nrmse_heatdata: NRMSE by [case, variable, ensemble member]\n",
    "#    where variable index 0-5 = variables in order of varlist, \n",
    "#                         6-8 = weighted average using even, structure, and\n",
    "#                               correlated weighted methods respectively\n",
    "\n",
    "# Concatenate data for error rate heatmap\n",
    "error_rate_wavg_array = np.stack([er_wavg_even,er_wavg_strct,er_wavg_corr],axis=1)\n",
    "error_heatdata = np.concatenate([error_rate_array,error_rate_wavg_array],axis=1)\n",
    "\n",
    "# Concatenate data for NRMSE heatmap\n",
    "nrmse_wavg_array = np.stack([nrmse_wavg_even,nrmse_wavg_strct,nrmse_wavg_corr],axis=1)\n",
    "nrmse_heatdata = np.concatenate([nrmse_array,nrmse_wavg_array],axis=1)\n",
    "\n",
    "# Metric/Variable labels\n",
    "heat_var_labels = [\"LAI\",\"AGB\",\"BA\",\n",
    "                \"GPP\",\"LH\",\"SH\",\"Av$_{E}$\",\"Av$_{S}$\",\"Av$_{C}$\"]\n",
    "\n",
    "# Ensemble member labels\n",
    "# For 10 highest performing ensemble members\n",
    "ens10 = [str(int(x)) for x in highperform_num]\n",
    "# For all ensemble members (label every 25th ensemble member)\n",
    "ens = np.array(range(25,300,25))\n",
    "enslist = [str(x) for x in ens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsubplotfxn(heatdata, casenum, minval, maxval, plotnum, metriclabel, highperform_indx, heat_var_labels, ens10):\n",
    "\n",
    "    #Subplot indexing paramter\n",
    "    i =2\n",
    "    \n",
    "    # Highest Performing Ensemble Members\n",
    "    ax1 = plt.subplot(3,i,plotnum)\n",
    "    im1 = ax1.imshow(heatdata[casenum,:,highperform_indx],vmin = minval, vmax = maxval,cmap=\"viridis_r\",aspect='auto')\n",
    "\n",
    "    ax1.set_xticks(np.arange(len(heat_var_labels)))\n",
    "    ax1.xaxis.tick_top()\n",
    "    ax1.set_xticklabels(heat_var_labels)\n",
    "    ax1.xaxis.set_label_position('top')\n",
    "\n",
    "    ax1.set_ylabel('High Performing Parameter Sets (#)')\n",
    "    ax1.set_yticks(np.arange(len(ens10)))\n",
    "    ax1.set_yticklabels(ens10)\n",
    "\n",
    "    # All Ensemble Members\n",
    "    ax2 = plt.subplot(3,i,(i+plotnum,i*2+plotnum))\n",
    "    im2 = ax2.imshow(np.transpose(heatdata[casenum,:,:]),vmin = minval, vmax = maxval,cmap=\"viridis_r\",aspect='auto')\n",
    "    # Create colorbar\n",
    "    cbar = ax1.figure.colorbar(im2, ax=ax2, orientation=\"horizontal\", pad=0.025)\n",
    "    cbar.ax.set_xlabel(metriclabel, fontsize = 16, fontweight ='bold')\n",
    "    ax2.set_xticks([]) # to hide xticks/labels\n",
    "\n",
    "    ax2.set_ylabel('All Parameter Sets (#)')\n",
    "    ax2.set_yticks(ens)\n",
    "    ax2.set_yticklabels(enslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case #1: Simulations run with approximate carbon dioxide concentration at the beginning of observational period (367 ppm CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set case to 367ppm CO2\n",
    "casenum = 0\n",
    "\n",
    "# Plot Error Rate\n",
    "plotnum = 1\n",
    "heatsubplotfxn(error_heatdata, casenum, 0, 100, plotnum, 'A.  Error Rate (%)', \n",
    "               highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "# Plot NRMSE\n",
    "plotnum = plotnum+1\n",
    "heatsubplotfxn(nrmse_heatdata, casenum, 0, 10, plotnum, 'B.  NRMSE', \n",
    "               highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case #2: Simulations run with approximate carbon dioxide concentration at the end of observational period (400 ppm CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set case to 400ppm CO2\n",
    "casenum = 1\n",
    "\n",
    "# Plot Error Rate\n",
    "plotnum = 1\n",
    "heatsubplotfxn(error_heatdata, casenum, 0, 100, plotnum, 'A.  Error Rate (%)',\n",
    "              highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "# Plot NRMSE\n",
    "plotnum = plotnum+1\n",
    "heatsubplotfxn(nrmse_heatdata, casenum, 0, 10, plotnum, 'B.  NRMSE',\n",
    "              highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

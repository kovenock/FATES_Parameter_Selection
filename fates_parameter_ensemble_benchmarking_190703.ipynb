{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FATES parameter ensemble evaluation \n",
    "\n",
    "This code evaluates the performance of 287 parameter ensemble member simulations against observations at a tropical forest test site, Barro Colorado Island, Panama. Parameter ensemble member simulations are identical (same model structure, initial conditions, and meteorological forcing) except that they differ in 12 plant trait parameters. Values for these plant trait parameters were sampled from observationally constrained distributions when possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil.parser\n",
    "import datetime\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifiy user defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of years of model output to analyze\n",
    "nyrs = 50\n",
    "\n",
    "# Model output\n",
    "# Filepath\n",
    "model_filepath = 'data/'\n",
    "# Model filenames where {1} = model_casenames, {2} = varfiletype\n",
    "model_filenames =[\n",
    "    'fates_clm5_fullmodel_bci_parameter_ensemble_1pft_slaprofile_{}_v001.I2000Clm50FatesGs.Cdf9b02d-Fb178808.2018-07-27.h{}.ensemble.sofar.nc',\n",
    "    'fates_clm5_fullmodel_bci_parameter_ensemble_1pft_slaprofile_{}_v001.I2000Clm50FatesGs.Cdf9b02d-Fb178808.2018-07-27.h{}.ensemble.sofar.nc']\n",
    "\n",
    "# Case names\n",
    "# We analyze results for two separate ensembles. One ensemble is run at 367ppm CO2, \n",
    "# the second at 400ppm CO2. These atmospheric CO2 concentrations are the approximate\n",
    "# concentrations at the beginning and end of the time period over which the observations\n",
    "# that we use in our benchmarking analysis were made.\n",
    "model_casenames = ['367ppm', '400ppm']\n",
    "\n",
    "# Variable list for model output\n",
    "varlist = ['TLAI','AGB','BA','GPP','FLH','FSH']\n",
    "\n",
    "# Variable file type\n",
    "# Model output differs in structure by variable.\n",
    "# varfiletype: 0 = monthly, no tree size structure; 1 = annual, tree size structured.\n",
    "# Order of varfiletype corresponds to variables in varlist.\n",
    "varfiletype = [0,1,1,0,0,0]\n",
    "\n",
    "# Variable conversion factor (order corresponds to varlist)\n",
    "varconv = [1, 1, 1, 86400*365, 1, 1]\n",
    "\n",
    "# Variable units after applying conversion factor (order corresponds to varlist)\n",
    "varunits = ['$m^2/m^2$','$kgC/m^2$','$m^2/ha$','$gC/m^2/yr$','$W/m^2$','$W/m^2$']\n",
    "\n",
    "# Degradation level for the observational range (as fractions, not percent)\n",
    "dg = np.array([0.10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multidimensional array to store model output data\n",
    "# model_data = [case, variable, ensemble member, time series]\n",
    "# case: 0 = ensemble run at 367ppm CO2; 1 = ensemble run at 400ppm CO2.\n",
    "# variable: \n",
    "    # 0 = Leaf area index\n",
    "    # 1 = Above ground biomass\n",
    "    # 2 = Basal area\n",
    "    # 3 = Gross primary productivity\n",
    "    # 4 = Latent heat flux\n",
    "    # 5 = Sensible heat flux\n",
    "# ensemble member: 0-286 = specifies randomly generated parameter set\n",
    "# timeseries: annual mean values for n years\n",
    "\n",
    "# Determine number of ensemble members for each model case\n",
    "nens = nc4.Dataset(model_filepath + model_filenames[0].format(model_casenames[0],varfiletype[0])).variables[varlist[0]].shape[0]\n",
    "\n",
    "# Empty array to be filled\n",
    "model_data = np.zeros([len(model_casenames), len(varlist), nens, nyrs])\n",
    "\n",
    "\n",
    "# Define a function to calculate time series of annual means for model output\n",
    "def annmeants(filepath,var,varfiletype,nyrs,conv_factor):\n",
    "    ''' Calculate time series of annual means for a model output variable.\n",
    "    :param filepath (str): file path to data file\n",
    "    :param var (str): name of variable to call from filename\n",
    "    :param nyrs (int, float): number of years to analyze\n",
    "    :param conv_factor (float): conversion factor specific to variable specified by var\n",
    "    :return: 2-D array containing annual mean time series [ensemble member, nyrs] \n",
    "    '''\n",
    "    \n",
    "    # If model output is stored as monthly average for all tree sizes,\n",
    "    # need to calculate annual mean.   \n",
    "    if varfiletype == 0:\n",
    "        \n",
    "        # Load monthly time series\n",
    "        # For all cases except latent heat flux (FLH):\n",
    "        if var != 'FLH':\n",
    "            mthts_temp = nc4.Dataset(filepath).variables[var][:,:,0]\n",
    "        \n",
    "        # For the special case of latent heat flux:\n",
    "        elif var == 'FLH':\n",
    "            # Sum of three terms:\n",
    "            mthts_temp = (nc4.Dataset(filepath).variables['FCTR'][:,:,0] \n",
    "                          + nc4.Dataset(filepath).variables['FGEV'][:,:,0] \n",
    "                          + nc4.Dataset(filepath).variables['FCEV'][:,:,0])\n",
    "        \n",
    "        \n",
    "        # Calculate annual mean time series for nyrs and convert units if necessary\n",
    "        annmeants = np.nanmean(np.reshape((mthts_temp[:,int(-1*nyrs*12):] * conv_factor),\n",
    "                                          (mthts_temp.shape[0],-1,12)),axis=2)\n",
    "        \n",
    "    # Else if model output is stored as annual mean but structured by tree size,\n",
    "    # need to sum across tree sizes.\n",
    "    elif varfiletype == 1:\n",
    "        # Calculate annual mean time series for entire ecosystem by summing across tree sizes\n",
    "        annmeants = np.squeeze(np.nansum((\n",
    "                        nc4.Dataset(filepath).variables[var + '_SCLS'][:,int(-1*nyrs):,:]),\n",
    "                        axis=2))\n",
    "    \n",
    "    mthts_temp = None\n",
    "    \n",
    "    return annmeants\n",
    "\n",
    "\n",
    "# Fill array with model output data\n",
    "for c in range(len(model_casenames)):\n",
    "    \n",
    "    for v in range(len(varlist)):      \n",
    "        \n",
    "        # Specify filepath for this case and variable\n",
    "        filepath = model_filepath + model_filenames[c].format(model_casenames[c],varfiletype[v])\n",
    "                \n",
    "        # Add data for this case and variable to model_data array\n",
    "        model_data[c, v, :, :] = annmeants(filepath, varlist[v], varfiletype[v], nyrs, varconv[v])\n",
    "\n",
    "        filepath = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross primary productivity, latent heat flux, and sensible heat fluxes\n",
    "\n",
    "Calculated from fluxtower data at Barro Colorado Island, Panama. Data from:<br>\n",
    "\n",
    "Koven, C. D., et al. Benchmarking and Parameter Sensitivity of Predictions of Ecophysiological and Vegetation Dynamics using the Functionally Assembled Terrestrial Ecosystem Simulator (FATES) at Barro Colorado Island, Panama. In prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section by Charles D. Koven, Lawrence Berkeley National Lab\n",
    "\n",
    "# Load and preprocess observations for GPP, LH, SH\n",
    "# This results in arrays with shape(6 years, 12 months) for:\n",
    "# gpp_gcm2y = timeseries of monthly mean gpp (gC/m2/yr); averaged across all 30min time points for each month)\n",
    "# LE_monthyear = timeseries of monthly mean latent heat flux(W/m2);\n",
    "# H_monthyear = timeseries of monthly mean sensible heat flux (W/m2);\n",
    "\n",
    "bci_fluxtower_datafilename = 'data/BCI_v3.1.csv'\n",
    "\n",
    "bci_fluxtower_data = np.genfromtxt(bci_fluxtower_datafilename, dtype={'names': ('date','tair','RH','vpd','p_kpa','PPT','Rs','Rs_dn','Rl_dn','Rl_up','Rnet','LE','H','Par_tot','Par_diff','SWC','ubar','ustar','WD','gpp','FLAG'),'formats': ('S16','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4')}, delimiter=',', skip_header=2)\n",
    "\n",
    "ntim = len(bci_fluxtower_data)\n",
    "\n",
    "time_start = datetime.datetime(2010, 1, 1, 0, 00)\n",
    "\n",
    "tdelt = np.ma.masked_all(ntim)\n",
    "month = np.ma.masked_all(ntim, dtype=np.int)\n",
    "year = np.ma.masked_all(ntim, dtype=np.int)\n",
    "gpp = np.ma.masked_all(ntim)\n",
    "LE = np.ma.masked_all(ntim)\n",
    "H = np.ma.masked_all(ntim)\n",
    "\n",
    "for i in range(ntim):\n",
    "    ts = dateutil.parser.parse(bci_fluxtower_data[i][0])\n",
    "    tdelt[i] = (ts - time_start).days + (ts - time_start).seconds / 86400.\n",
    "    month[i] = ts.month\n",
    "    year[i] = ts.year\n",
    "    gpp[i] = bci_fluxtower_data[i][19]\n",
    "    LE[i] = bci_fluxtower_data[i][11]\n",
    "    H[i] = bci_fluxtower_data[i][12]\n",
    "\n",
    "H_masked = np.ma.masked_invalid(H)\n",
    "\n",
    "nyears = (year.max() - year.min()) + 1\n",
    "nmonths = nyears * 12\n",
    "\n",
    "gpp_monthly = np.ma.masked_all(nmonths)\n",
    "gpp_monthyear = np.ma.masked_all([nyears,12])\n",
    "LE_monthyear = np.ma.masked_all([nyears,12])\n",
    "H_monthyear = np.ma.masked_all([nyears,12])\n",
    "\n",
    "for i in range(nyears):\n",
    "    for j in range(12):\n",
    "        mask = (year[:] == (year.min() + i)) * (month[:] == (j + 1))\n",
    "        index = i*12 + j\n",
    "        # gpp_monthly2[index] = gpp[mask].mean()                                                                                                                                                                                                                              \n",
    "        if mask.sum() > 0:\n",
    "            gpp_monthly[index] = (gpp * mask).sum() / mask.sum()\n",
    "            gpp_monthyear[i,j] = gpp_monthly[index]\n",
    "            LE_monthyear[i,j] = (LE * mask).sum() / mask.sum()\n",
    "        H_monthyear[i,j] = H_masked[mask].mean()\n",
    "\n",
    "months = np.arange(12)\n",
    "\n",
    "### change gpp units to grams or carbon per meter squared per year\n",
    "gpp_gcm2y = gpp_monthyear * 1e-6 * 12.0107 * (86400 * 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annual mean values for gross primary productivity, latent heat flux, and sensible heat flux\n",
    "# Results in obs_data_flux = annual means indexed by [startmonth (0 = July, 1= Sept), variable, year]\n",
    "#    variable: 0 = gross primary productivity, 1 = latent heat flux, 2 = sensible heat flux\n",
    "#    startmonth: index for annual mean calculations starting from different months\n",
    "#        There are two time series for each variable because the observations span incomplete years.\n",
    "#        To use all data available in our analysis, we calculate have one time series of means \n",
    "#        starting with July and the second starting with Sept (this uses all months available).\n",
    "#    year: year in the annual mean time series\n",
    "\n",
    "# Function to calculate annual mean time series from monthly data\n",
    "def annmeants_fluxobs(mthts,startmth):\n",
    "    ''' Calculate time series of annual means from fluxtower estimates.\n",
    "    :param mthts (float): 2-D array containing fluxtower observations [years, months]\n",
    "    :param startmth (int): number corresponding to start month for this annual mean time series\n",
    "                            (e.g. 7 = start with July, 9 = start with Sept)\n",
    "    :return: vector containing annual mean time series [nyrs] \n",
    "    '''\n",
    "    # Discard number of months specified by dif\n",
    "    mthts_dif = np.reshape(mthts,(1,-1))[:,startmth-1:startmth-1-12]\n",
    "    # Calculate annual mean time series\n",
    "    annmeants = np.nanmean(np.reshape(mthts_dif,(5,12)),axis=1)\n",
    "    \n",
    "    return annmeants\n",
    "\n",
    "# Specify start months for observations\n",
    "startmonth_list = np.array([7,9])\n",
    "\n",
    "# Number of years\n",
    "nyrs_obsflux = len(annmeants_fluxobs(gpp_gcm2y,startmonth_list[0]))\n",
    "\n",
    "# Create empty array to fill with observation time series for GPP, LH, SH\n",
    "obs_data_flux = np.zeros([len(startmonth_list), 3, nyrs_obsflux])\n",
    "\n",
    "for x in range(len(startmonth_list)):\n",
    "    obs_data_flux[x,0,:] = annmeants_fluxobs(GPP_monthyear,startmonth_list[x])\n",
    "    obs_data_flux[x,1,:] = annmeants_fluxobs(LE_monthyear,startmonth_list[x])\n",
    "    obs_data_flux[x,2,:] = annmeants_fluxobs(H_monthyear,startmonth_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaf area index observations\n",
    "\n",
    "Data was captured using GraphClick software from Figure 7a of: <br>\n",
    "Detto, M., Wright, S. J., Calderón, O., & Muller-Landau, H. C. (2018). Resource acquisition and reproductive strategies of tropical forest in response to the El Niño-Southern Oscillation. Nature Communications, 9(1), 913. https://doi.org/10.1038/s41467-018-03306-9\n",
    "\n",
    "Note. Monthly data consists of spatial means across 188 locations taken approximately once a month within our test site (not temporal means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_lai: 2D array containing annual mean leaf area index [sample number, years]\n",
    "#    sample: 0 = sample months starting from January; 1 = starting from Sept\n",
    "#    Note. As observations consist of 2 years and 8 months of data, we sample both\n",
    "#    the first set of full years (starting in January) and last set of full years\n",
    "#    (starting in September)\n",
    "\n",
    "# File path\n",
    "filepath = 'data/LAI_Detto2018Obs.csv'\n",
    "\n",
    "# Monthly spatial means\n",
    "lai_mthts = np.asarray([col[2] for col in (pd.read_csv(filepath)).values])\n",
    "\n",
    "# Specify start months for observations\n",
    "startmonth_list = np.array([1,9])\n",
    "\n",
    "# Number of annual means per sample\n",
    "nyears_lai = round(len(lai_mthts)/12-0.5)\n",
    "\n",
    "# Empty array to be filled [sample number, years]\n",
    "obs_data_lai = np.zeros([len(startmonth_list), nyears_lai])\n",
    "\n",
    "# Calculate annual means (starting in January, then in September)\n",
    "for x in range(len(startmonth_list)):\n",
    "    obs_data_lai[x,:] = np.nanmean(np.reshape(lai_mthts[startmonth_list[x]-1:24+startmonth_list[x]-1],(nyears_lai,12)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above-ground biomass observations\n",
    "\n",
    "Data from:\n",
    "\n",
    "Meakem, V., Tepley, A. J., Gonzalez-Akre, E. B., Herrmann, V., Muller-Landau, H. C., Wright, S. J., et al. (2018). Role of tree size in moist tropical forest carbon cycling and water deficit responses. New Phytologist, 219, 947–958. https://doi.org/doi:10.1111/nph.14633\n",
    "<br>\n",
    " \n",
    "Baraloto, C., Molto, Q., Rabaud, S., Hérault, B., Valencia, R., Blanc, L., et al. (2013). Rapid simultaneous estimation of aboveground biomass and tree diversity across Neotropical forests: a comparison of field inventory methods. Biotropica, 45(3), 288–298. https://doi.org/10.1111/btp.12006 \n",
    "<br>\n",
    "\n",
    "Feeley, K. J., Davies, S. J., Ashton, P. S., Bunyavejchewin, S., Supardi, M. N., Kassim, A. R., et al. (2007). The role of gap phase processes in the biomass dynamics of tropical forests. Proceedings of the Royal Society of London B: Biological Sciences, 274(1627), 2857–2864. https://doi.org/10.1098/rspb.2007.0954\n",
    "<br>\n",
    "\n",
    "Note. We use the range across two different allometry (i.e. tree shape) calculations (standard and Chave) from Meakem et al. (2018) to bracket the overall uncertainty in biomass. Alternatively, we could estimate carbon biomass from biomass reported in Baraloto et al. (2013) and Feeley et al. (2007). This alternative method was tested an yeilds similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_agb: vector of above ground biomass (KgC/m2)\n",
    "#    from estimates from Meakem et al. 2018 [allometry calculation] \n",
    "#   allometry calculation: 0 = standard, 1 = Chave\n",
    "\n",
    "filepath = 'data/BCI_biomass.csv'\n",
    "\n",
    "# Carbon above ground biomass from Meakem et al. 2018 (MgC/ha) \n",
    "cbiomass_obs_Mgha = np.asarray([col[2] for col in (pd.read_csv(filepath)).values])[-2:,]\n",
    "# Convert from MgC/ha to KgC/m2\n",
    "ha_to_m2 = 1/10000\n",
    "Mg_to_kg = 1000\n",
    "obs_data_agb = cbiomass_obs_Mgha * ha_to_m2 * Mg_to_kg\n",
    "\n",
    "# Alternatively could use the following in our analysis by\n",
    "# uncommenting the last line here (results are similar)\n",
    "# Total aboveground biomass (Mg biomass/ha) from census data \n",
    "# (Baraloto et al. 2013, Biotropica; Feeley et al. 2007, Proc Roy Soc B)\n",
    "# Years: 2005,1985,1990,1995,2000,2005\n",
    "agb_biomass_obs = np.asarray([col[1] for col in (pd.read_csv(filepath)).values])[:-2,]\n",
    "# Estimate of carbon biomass from biomass using scaler of 0.47 following Meakem et al. 2018\n",
    "obs_data_agb_v2 = agb_biomass_obs*0.47\n",
    "#obs_data_agb = obs_data_agb_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basal area observations\n",
    "\n",
    "Data from census surveys of a 50-hectare plot on Barro Colorado Island, Panama, from:\n",
    "\n",
    "Condit, R. S., Aguilar, S., Perez, R., Lao, S., Hubbell, S. P., & Foster, R. B. (2017). Barro Colorado 50-ha Plot Taxonomy as of 2017. https://doi.org/10.25570/stri/10088/32990\n",
    "\n",
    "Condit, R., Lao, S., Pérez, R., Dolins, S. B., Foster, R., & Hubbell, S. (2012). Barro Colorado forest census plot data (version 2012). Center for Tropical Forest Science Databases. Https://Dx. Doi. Org/10.5479/Data. Bci. https://doi.org/http://dx.doi.org/10.5479/data.bci.20130603\n",
    "\n",
    "Condit, R. (1998). Tropical forest census plots. Berlin, Germany, and Georgetown, Texas: Springer-Verlag and R. G. Landes Company.\n",
    "\n",
    "Hubbell, S. P., Foster, R. B., O'Brien, S. T., Harms, K. E., Condit, R., Wechsler, B., et al. (1999). Light-gap disturbances, recruitment limitation, and tree diversity in a neotropical forest. Science, 283(5401), 554–557. https://doi.org/10.1126/science.283.5401.554 \n",
    "\n",
    "Note. Data from 1992, 1996, 2001, 2006, and 2011 are used herein. Previous census years are excluded for consistency as a different measurement method was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return: obs_data_ba: vector containing basal area (m^2/ha) by census year [years]\n",
    "\n",
    "filepath = 'data/census_bmks_bci_171208.nc'\n",
    "\n",
    "# Load basal area median values for the last 5 census dates\n",
    "# Data stored in filepath as [census number, tree diameter size class, distribution percentiles (0.05,0.5,0.95)]\n",
    "basalarea_bysize = nc4.Dataset(filepath).variables['basal_area_by_size_census'][-5:,:,1]\n",
    "# Calculate total median value for site by summing across tree size classes\n",
    "obs_data_ba = np.nansum(basalarea_bysize,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance of each parameter ensemble member against observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #1: Error Rate\n",
    "\n",
    "The error rate measures the percent of model annual means that fall within observed range for each variable and ensemble member.<br>\n",
    "\n",
    "The observed range is defined as the minimum and maximum across observations. To account for relatively small sample sizes and potential measurment error within the observations we extend the observational range by the 10% in either direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return:  error_rate_array: a 4-D array containing error rates\n",
    "#    [case, variable, model ensemble member, degradation level]\n",
    "\n",
    "# Specify names of observed data arrays in order corresponding to varlist\n",
    "obs_data_list = [obs_data_lai,obs_data_agb,obs_data_ba,\n",
    "                 obs_data_flux[:,0,:],obs_data_flux[:,1,:],\n",
    "                 obs_data_flux[:,2,:]]\n",
    "\n",
    "\n",
    "#Function to calculate error rate \n",
    "def error_rate(model_ts,obs_ts,dg):\n",
    "    '''Function calculates the error rate, meaning the percentage of\n",
    "    model annual means that fall within the observed range for each model\n",
    "    ensemble member\n",
    "    param model_ts: a 2-D array containing the time series of annual means\n",
    "       for a given variable for all model ensemble members [ensemble member, years]\n",
    "    param obs_ts: an n-D array containing the observed time series for\n",
    "        the given variable\n",
    "    param dg: a vector of any length specifying the levels of range degradation\n",
    "        to test\n",
    "    return error_rate: a 2-D array containing the error rates for each \n",
    "        ensemble member [ensemble member, degradation rates (dg)]'''\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    nens = model_ts.shape[0]\n",
    "    \n",
    "    # Empty array to fill\n",
    "    error_rate = np.zeros([nens])\n",
    "\n",
    "    # Observed minimum and maximum\n",
    "    obs_min = np.nanmin(obs_ts)\n",
    "    obs_max = np.nanmax(obs_ts)\n",
    "    \n",
    "    error_rate = 100*np.nansum(np.where((model_ts <= obs_min*(1-dg)) | (model_ts >= obs_max*(1+dg)),1,0),1)/model_ts.shape[1]\n",
    "    return error_rate\n",
    "\n",
    "\n",
    "# Calculate error rate for all cases and variables\n",
    "error_rate_array = np.zeros([len(model_casenames),len(varlist), nens])\n",
    "for i in range(len(model_casenames)):\n",
    "        for j in range(len(varlist)):\n",
    "            error_rate_array[i,j,:] = error_rate(model_data[i,j,:,:], obs_data_list[j], dg)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #2:  Normalized root mean square error (NRMSE)\n",
    "\n",
    "The normalized root mean square error (NRMSE) measures the distance between each ensemble member's model output from the observed mean and normalizes this distance by the observed range. The normalized root mean square error is calculated for each variable and ensemble member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalized Root Mean Square Error (RMSE/Observed Range)\n",
    "# Returns nrsmse_array a 3-D array containing NRMSE for each \n",
    "#[case, variable, ensemble member]\n",
    "\n",
    "# Function to calculate normalized root mean square errer (nrmse)\n",
    "# When multiple observation time series are available, this function\n",
    "# calculates the nrmse for each time series and then selects the \n",
    "# lowest of those nrmse values.\n",
    "def nrmse(model_ts,obs_ts):\n",
    "    '''Function calculates the normalized root mean square error for each model\n",
    "    ensemble member\n",
    "    param model_ts: a 2-D array containing the time series of annual means\n",
    "       for a given variable for all model ensemble members [ensemble member, years]\n",
    "    param obs_ts: an n-D array containing the observed time series for\n",
    "        the given variable\n",
    "    return nrmse: a vector containing the normalized root mean square error \n",
    "        for each ensemble member [ensemble member]'''\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    nens = model_ts.shape[0]\n",
    "\n",
    "    # If multiple observation time series, \n",
    "    # take the lowest NRMSE for each ensemble member\n",
    "    try:\n",
    "        if obs_ts.shape[1]>0:\n",
    "            # Number of observation time series\n",
    "            nobs = obs_ts.shape[0]\n",
    "            obs_min = np.nanmin(obs_ts,axis=1)\n",
    "            obs_max = np.nanmax(obs_ts, axis=1)\n",
    "            obs_mean = np.nanmean(obs_ts,axis=1)\n",
    "            \n",
    "            temp_nrmse = np.zeros([nobs,nens])\n",
    "            \n",
    "            for obsnum in range(nobs):\n",
    "                temp_nrmse[obsnum,:] = np.sqrt(np.nansum((obs_mean[obsnum] - model_ts[:,:])**2,axis=1) / model_ts.shape[1]) / (obs_max[obsnum]-obs_min[obsnum])\n",
    "                \n",
    "            nrmse = np.nanmin(temp_nrmse,axis=0)\n",
    "\n",
    "            temp_nrmse = None\n",
    "        \n",
    "    # Otherwise, simply calculate NRMSE\n",
    "    except IndexError:\n",
    "        obs_min = np.nanmin(obs_ts,axis=0)\n",
    "        obs_max = np.nanmax(obs_ts,axis=0)\n",
    "        obs_mean = np.nanmean(obs_ts,axis=0)    \n",
    "        \n",
    "        nrmse = np.sqrt(np.nansum((obs_mean - model_ts[:,:])**2,axis=1) / model_ts.shape[1]) / (obs_max-obs_min)\n",
    "\n",
    "    return nrmse\n",
    "    \n",
    "\n",
    "# Calculate NRMSE for all cases and variables\n",
    "nrmse_array = np.zeros([len(model_casenames),len(varlist), nens])\n",
    "\n",
    "for i in range(len(model_casenames)):\n",
    "        for j in range(len(varlist)):\n",
    "            nrmse_array[i,j,:] = nrmse(model_data[i,j,:,:], obs_data_list[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average across variables\n",
    "\n",
    "We calculate weighted averages across variables for both the normalized root mean square error and the error rate. We calculate and consider three different weighting approaches to ensure that our selection of high-performing parameter sets is robust to weighting method. These three weighting approaches we use are:\n",
    "\n",
    "1. Even:  All variables are evenly weighted.\n",
    "\n",
    "2. Structure:  This weighting favors structural ecosystem properties (leaf area index, above-ground biomass, and basal area). This weighting scheme reflects the likelihood that structural property measurements at our test site include less uncertainty than flux measurements.\n",
    "\n",
    "3. Correlation: This weighting scheme is informed by correlations between individual variable scores. Ensemble member performance in flux variables (gross primary productivity, sensible heat, and latent heat) was correlated with leaf area index and with one another. As leaf area index observations likely include smaller measurement uncertainty, we chose to weight leaf area index more highly at the expense of flux observations. We also reduced the weightings of basal area and above-ground biomass to account for their correlation with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even weighting across all variables\n",
    "er_wavg_even = np.nansum(error_rate_array,1) / error_rate_array.shape[1]\n",
    "\n",
    "\n",
    "# Weighted average favoring structural properties:\n",
    "# leaf area index, aboveground biomass, basal area\n",
    "w = 0.3\n",
    "er_wavg_strct = ( w*(error_rate_array[:,0,:]) \n",
    "            + w*(error_rate_array[:,1,:])\n",
    "            + w*(error_rate_array[:,2,:])\n",
    "            + (1-3*w)*((error_rate_array[:,3,:])\n",
    "                +(error_rate_array[:,4,:])\n",
    "                +(error_rate_array[:,5,:]))/3)\n",
    "\n",
    "# Alternative weighting based on correlations between error rates across variables\n",
    "# 1. Weighted average giving greatest weight to LAI, then to combination of AGB and BA (which are correlated with one another),\n",
    "# and small weight to fluxes which are correlated with one another and with LAI.\n",
    "w1 = 0.4\n",
    "w2 = 0.25\n",
    "w3 = 0.1\n",
    "er_wavg_corr = ( w1*(error_rate_array[:,0,:])  \n",
    "            + w2*(error_rate_array[:,1,:])  \n",
    "            + w2*(error_rate_array[:,2,:]) \n",
    "            + w3*((error_rate_array[:,3,:])\n",
    "                +(error_rate_array[:,4,:])\n",
    "                +(error_rate_array[:,5,:]))/3)\n",
    "\n",
    "# Note. Code for er_wavg_strct and er_wavg_corr should be updated \n",
    "# to allow the flexibility to add additional variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted average Distance scores\n",
    "# Here we use the weighted Euclidean Distance to calculate the distance of model output from the mean observations in multivariate space:\n",
    "#  Square each variable score before weighting, then take squareroot of the weighted sum;\n",
    "#  Use the time period that fits model output best (e.g. jan vs sept start)\n",
    "\n",
    "\n",
    "# Weighted average with even weighting across all variables\n",
    "w = 1/6\n",
    "nrmse_wavg_even = np.sqrt(w*(nrmse_array[:,0,:])**2 \n",
    "                                  + w*(nrmse_array[:,1,:])**2 \n",
    "                                  + w*(nrmse_array[:,2,:])**2 \n",
    "                                  + w*(nrmse_array[:,3,:])**2 \n",
    "                                  + w*(nrmse_array[:,4,:])**2 \n",
    "                                  + w*(nrmse_array[:,5,:])**2)\n",
    "\n",
    "\n",
    "# Define weighted average favoring LAI, AGB, and BA (our structural properties)\n",
    "w = 0.3\n",
    "nrmse_wavg_strct = np.sqrt(w*(nrmse_array[:,0,:])**2 \n",
    "                        + w*(nrmse_array[:,1,:])**2 \n",
    "                        + w*(nrmse_array[:,2,:])**2 \n",
    "                        + (1-3*w)*((nrmse_array[:,3,:])**2 \n",
    "                                    +(nrmse_array[:,4,:])**2 \n",
    "                                    +(nrmse_array[:,5,:])**2)/3)\n",
    "\n",
    "# Weighted average giving greatest weight to LAI, then to combination of AGB and BA (which are correlated with one another),\n",
    "# and small weight to fluxes which are correlated with one another and with LAI.\n",
    "w1 = 0.4\n",
    "w2 = 0.25\n",
    "w3 = 0.1\n",
    "nrmse_wavg_corr = np.sqrt(w1*(nrmse_array[:,0,:])**2 \n",
    "                          + w2*(nrmse_array[:,1,:])**2 \n",
    "                          + w2*(nrmse_array[:,2,:])**2 \n",
    "                          + w3*((nrmse_array[:,3,:])**2 \n",
    "                                  +(nrmse_array[:,4,:])**2 \n",
    "                                  +(nrmse_array[:,5,:])**2)/3)\n",
    "\n",
    "# Note. The above code should be updated \n",
    "# to allow the flexibility to add additional variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank ensemble members by performance\n",
    "Here we assign an overall rank to each ensemble member based on its performance across both performance metrics (error rate and NRMSE), a three weighting schemes (even, structure, and correlated), and two cases (low and high atmospheric carbon dioxide concentration). The goal of this analysis is to identify parameter ensemble members (and thus parameter sets) that robsutly perform well at our test site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_array = np.stack([er_wavg_even,nrmse_wavg_even,\n",
    "                             er_wavg_strct,nrmse_wavg_strct,\n",
    "                             er_wavg_corr,nrmse_wavg_corr])\n",
    "\n",
    "rank_array = scipy.stats.mstats.rankdata(all_avg_array,axis=2)\n",
    "\n",
    "# Sum ranks across cases and ranking methods\n",
    "sum_rank_array = np.nansum(np.nansum(rank_array,axis=0),axis=0)\n",
    "\n",
    "# Sort the index number for each ensemble member by their summed rank (best to worst performance)\n",
    "sum_rank_index = np.argsort(sum_rank_array)\n",
    "\n",
    "#Print Index # for Top 10 Ensemble Members\n",
    "highperform_num = np.transpose(sum_rank_index)[:10,]+1\n",
    "highperform_indx = np.transpose(sum_rank_index)[:10,]\n",
    "print(\"Highest Performing Ensemble Member Numbers: \", highperform_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance metrics for high-performing and all ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param dg: specifies degradation level of observational range\n",
    "# return error_heatdata: error rates by [case, variable, ensemble member]\n",
    "# return nrmse_heatdata: NRMSE by [case, variable, ensemble member]\n",
    "#    where variable index 0-5 = variables in order of varlist, \n",
    "#                         6-8 = weighted average using even, structure, and\n",
    "#                               correlated weighted methods respectively\n",
    "\n",
    "# Concatenate data for error rate heatmap\n",
    "error_rate_wavg_array = np.stack([er_wavg_even,er_wavg_strct,er_wavg_corr],axis=1)\n",
    "error_heatdata = np.concatenate([error_rate_array,error_rate_wavg_array],axis=1)\n",
    "\n",
    "# Concatenate data for NRMSE heatmap\n",
    "nrmse_wavg_array = np.stack([nrmse_wavg_even,nrmse_wavg_strct,nrmse_wavg_corr],axis=1)\n",
    "nrmse_heatdata = np.concatenate([nrmse_array,nrmse_wavg_array],axis=1)\n",
    "\n",
    "# Metric/Variable labels\n",
    "heat_var_labels = [\"LAI\",\"AGB\",\"BA\",\n",
    "                \"GPP\",\"LH\",\"SH\",\"Av$_{E}$\",\"Av$_{S}$\",\"Av$_{C}$\"]\n",
    "\n",
    "# Ensemble member labels\n",
    "# For 10 highest performing ensemble members\n",
    "ens10 = [str(int(x)) for x in highperform_num]\n",
    "# For all ensemble members (label every 25th ensemble member)\n",
    "ens = np.array(range(25,300,25))\n",
    "enslist = [str(x) for x in ens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsubplotfxn(heatdata, casenum, minval, maxval, plotnum, metriclabel, highperform_indx, heat_var_labels, ens10):\n",
    "\n",
    "    #Subplot indexing paramter\n",
    "    i =2\n",
    "    \n",
    "    # Highest Performing Ensemble Members\n",
    "    ax1 = plt.subplot(3,i,plotnum)\n",
    "    im1 = ax1.imshow(heatdata[casenum,:,highperform_indx],vmin = minval, vmax = maxval,cmap=\"viridis_r\",aspect='auto')\n",
    "\n",
    "    ax1.set_xticks(np.arange(len(heat_var_labels)))\n",
    "    ax1.xaxis.tick_top()\n",
    "    ax1.set_xticklabels(heat_var_labels)\n",
    "    ax1.xaxis.set_label_position('top')\n",
    "\n",
    "    ax1.set_ylabel('High Performing Parameter Sets (#)')\n",
    "    ax1.set_yticks(np.arange(len(ens10)))\n",
    "    ax1.set_yticklabels(ens10)\n",
    "\n",
    "    # All Ensemble Members\n",
    "    ax2 = plt.subplot(3,i,(i+plotnum,i*2+plotnum))\n",
    "    im2 = ax2.imshow(np.transpose(heatdata[casenum,:,:]),vmin = minval, vmax = maxval,cmap=\"viridis_r\",aspect='auto')\n",
    "    # Create colorbar\n",
    "    cbar = ax1.figure.colorbar(im2, ax=ax2, orientation=\"horizontal\", pad=0.025)\n",
    "    cbar.ax.set_xlabel(metriclabel, fontsize = 16, fontweight ='bold')\n",
    "    ax2.set_xticks([]) # to hide xticks/labels\n",
    "\n",
    "    ax2.set_ylabel('All Parameter Sets (#)')\n",
    "    ax2.set_yticks(ens)\n",
    "    ax2.set_yticklabels(enslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case #1: Simulations run with approximate carbon dioxide concentration at the beginning of observational period (367 ppm CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set case to 367ppm CO2\n",
    "casenum = 0\n",
    "\n",
    "# Plot Error Rate\n",
    "plotnum = 1\n",
    "heatsubplotfxn(error_heatdata, casenum, 0, 100, plotnum, 'A.  Error Rate (%)', \n",
    "               highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "# Plot NRMSE\n",
    "plotnum = plotnum+1\n",
    "heatsubplotfxn(nrmse_heatdata, casenum, 0, 10, plotnum, 'B.  NRMSE', \n",
    "               highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case #2: Simulations run with approximate carbon dioxide concentration at the end of observational period (400 ppm CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set case to 400ppm CO2\n",
    "casenum = 1\n",
    "\n",
    "# Plot Error Rate\n",
    "plotnum = 1\n",
    "heatsubplotfxn(error_heatdata, casenum, 0, 100, plotnum, 'A.  Error Rate (%)',\n",
    "              highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "# Plot NRMSE\n",
    "plotnum = plotnum+1\n",
    "heatsubplotfxn(nrmse_heatdata, casenum, 0, 10, plotnum, 'B.  NRMSE',\n",
    "              highperform_indx, heat_var_labels, ens10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
